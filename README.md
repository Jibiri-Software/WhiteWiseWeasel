# We are White Wise Weasel!!!!!!!!!!!!!

####1. Description
Our project is oriented to develop a navigator plugin and a webpage. The main idea is to protect our users from frauds, hoaxes and any kind of misleading warning. Users will be the ones to provide feedback to the app, using a system of points. Once the content has been reported a determined number of times, it will move to the page mods, who will determine if its malicious or not.

We are also aiming to unravel scam companies, based on the feedback provided with the system of points.

In style therms, the appearance will be simple and clear at first, but once we have gained some experience and users, once everything is working, we may give it a game-like* skin to act as publicity to attract young users to the platform, following the perspective of Discord for example. 
A system of acknowledgements and achievements could be included to motivate users to stay active. Maybe with help of sponsors, or even giveaways.

Although it will be somewhat automatic, there should always be a human part to decide whether a polemic element has been made by malicious individuals or not.

Users will have a “trust factor” that will be based on the efficiency rate of each user, raising with each verified hoax, and reduced by every mistake, the higher the trust factor, the more its reports counts. Users should  give reasons and sources about why a post is thought to be fake, increasing the validity of its report.

We could also count the resources some companies spent in storage and analyzing of spam and hoaxes. 

  *The idea of the skin is to change that every user has a points of attack, and so, posts have health points. If you have proven to be an active and helpful user, you’ll deal more damage, and so, your opinion is very valuable. Once the hp is taken down to 0, admins and mods will personally tell if that is fake or not. (Changing)

*The idea of the skin is to change the way the webpage and reports page looks, making it feel like you are battling while reporting a hoax, we would rename some of the parameters like the trust factors being your damage, the validity of a post being its health, and once it reaches 0 (a threshold we determine  before checking it), a mod/admin will check it and all the sources and confirm if it is fake or not.

####2.- Viability analysis

The project would have an slow beginning, due to the lack of a great number of mods and admins, but it will become more efficient eventually.

In general, it doesn’t require economic risks and we have the material resources needed to carry out the project. The main threat in our case would be human resources. Being honest, the team is not really experimented on Software development and moreover, we count with a strict deadline (6 of june). The main and decisive factor would be an excellent planning and strategy in order to assign human resources efficiently. Making any kind of mistake would mean to not completing the project. That’s why it is fundamental to make sure that the idea is consistent.

If users vote as a hoax something that isn’t really a hoax (let’s say unintentionally) it wouldn’t be a great problem. All contents voted would make it through a second filter done by mods and admins. Those mods would be users that have proved their integrity and reliability.

With a good reward system, it would be viable to create a great group of people that state that a content is a hoax in any website or social network.

The creation of the database wouldn’t also be a problem. It will include the elements based on users content and, by a manual supervision, it is possible to delete those contents that shouldn’t be on the database.

We also have thought about the possibility of taking into account the intellectual property thefts. However, after discussing for a while, we reached the conclusion that it would be extremely difficult to find the original author of any content. For instance, a person that submits to a website an illustration and gets economical benefits for that, instead of its real author. Finding the origin of a work, that could have been uploaded by different people, makes a correct database classification much more difficult.

We thought to demand for a mention to the original author of the content too. But we reached the same conclusion. Moreover, when publishing a work in different platforms, the author loses his copyright. So the task of protecting the intellectual property becomes even harder.

Lastly, we should mention that in some social networks as Reddit or Twitter, there are already users that let the community know which content is true and which is not. The thing is that the information is sometimes repeated by different users and it’s hard to warn all the community.This is what we want to provide, unification.

####3.- Requirements

(to do in a near future)

####4.- Planning

We discussed the differents ways of developing a project without really reaching a consensus. Until now, the spiral model is the one more appealing to us. Time is our major enemy so in case we couldn’t finish the project we would have some part done. With a non incremental model, we risk all or nothing, which would damage the viability of the project.

Task: In the next meeting each member would decide which is the model that he prefers and will defend in front of the rest. Then we will decide all together which is the best one.
